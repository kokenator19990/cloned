# Reporte de Desarrollo T√©cnico: Cloned
**Fecha:** 09 de Febrero de 2026
**Versi√≥n:** 1.2.0 (Voice-Centric Beta)

## 1. Resumen Ejecutivo
**Cloned** es una aplicaci√≥n web progresiva dise√±ada para crear "Clones Digitales" de alta fidelidad emocional. A diferencia de un chatbot est√°ndar, el valor central de Cloned es la **preservaci√≥n de la esencia humana** a trav√©s de la voz, el razonamiento y las expresiones, capturadas mediante un proceso de entrevista exhaustiva.

El objetivo final es permitir interacciones futuras con seres queridos (o con uno mismo) a trav√©s de una interfaz de avatar animado que no solo responde *qu√©* dir√≠a la persona, sino *c√≥mo* lo dir√≠a.

---

## 2. Arquitectura del Sistema

### 2.1 Stack Tecnol√≥gico
- **Frontend:** Next.js 14 (React), TypeScript, Tailwind CSS.
- **State Management:** Zustland (con persistencia en `localStorage`).
- **Audio Processing:** Web Audio API (MediaRecorder para captura, SpeechSynthesis para TTS).
- **Speech-to-Text (STT):** Web Speech API (reconocimiento nativo del navegador).
- **Persistencia de Datos:** LocalStorage (actualmente Client-Side Only para privacidad y rapidez en MVP).

### 2.2 Estructura de Componentes
El sistema se divide en tres m√≥dulos principales:

1.  **M√≥dulo de Ingesta (Interview Engine):**
    *   **Prop√≥sito:** Capturar la data cognitiva y biom√©trica (voz).
    *   **Flujo:** `Pregunta (TTS)` ‚Üí `Reflexi√≥n` ‚Üí `Respuesta (Voz)` ‚Üí `Transcripci√≥n (STT)`.
    *   **L√≥gica:** Sistema de profundidad progresiva (B√°sico ‚Üí Profundo ‚Üí Experto).

2.  **M√≥dulo de Simulaci√≥n (Neural Core - Simulado):**
    *   **Prop√≥sito:** Generar respuestas coherentes basadas en la base de conocimiento personal.
    *   **L√≥gica Actual:** Motor de coincidencia sem√°ntica (palabras clave + contexto de categor√≠a) + Fallback probabil√≠stico.
    *   **Capacidad:** Prioriza reproducir grabaciones de voz originales ("Audio de Verdad") sobre TTS sintetizado.

3.  **M√≥dulo de Interfaz (Talking Avatar):**
    *   **Prop√≥sito:** Humanizar la interacci√≥n mediante feedback visual.
    *   **Componente:** `TalkingAvatar.tsx`.
    *   **Caracter√≠sticas:** Animaciones CSS de respiraci√≥n, pulso de voz, anillos de emisi√≥n y "blink" de ojos (simulado).

---

## 3. Funcionalidades Actuales (Estado: Funcional)

### ‚úÖ Creaci√≥n de Perfil "Sin Fricci√≥n"
*   Flujo de onboarding instant√°neo sin registro (No-Auth).
*   Captura de datos iniciales: Nombre + Foto (C√°mara/Upload).

### ‚úÖ Entrevista de Voz Interactiva
*   **Banco de Preguntas:** 500 preguntas curadas en 10 categor√≠as (Valores, Humor, Recuerdos, etc.).
*   **Auto-Entrevistador:** La app "lee" las preguntas en voz alta para generar una atm√≥sfera de conversaci√≥n.
*   **Captura H√≠brida:** Graba el audio real (blob) Y transcribe a texto simult√°neamente.
*   **Visualizaci√≥n:** Waveform animado en tiempo real durante la grabaci√≥n.

### ‚úÖ Sistema de Profundidad (Gamificaci√≥n)
*   Niveles de fidelidad del clon basados en la cantidad y calidad de data:
    *   üü¢ **B√°sico:** < 50 respuestas.
    *   üîµ **Profundo:** 50-100 respuestas.
    *   üü£ **Experto:** 100-200 respuestas.
    *   üü† **Maestro:** > 200 respuestas + alta densidad de voz.

### ‚úÖ Chat Inmersivo (Modo "Selfie")
*   Interfaz de videollamada simulada.
*   **Avatar Reactivo:** El avatar crece y "brilla" cuando est√° hablando.
*   **Dual Mode Playback:**
    1.  Si hay grabaci√≥n exacta: Reproduce la VOZ REAL del usuario.
    2.  Si es inferencia: Usa TTS (Text-to-Speech) para sintetizar la respuesta.

---

## 4. Funcionalidades Potenciales (Roadmap)

### üöÄ Corto Plazo
*   **Voice Cloning Real (IA):** Integrar ElevenLabs o similar para que el TTS use la voz *clonada* del usuario, no la rob√≥tica del navegador.
*   **Exportar/Importar Perfil:** Permitir descargar el "cerebro" (JSON + Audio Blobs) para guardarlo o enviarlo a un familiar.

### üåü Mediano Plazo
*   **RAG (Retrieval-Augmented Generation):** Conectar un LLM local (ej. WebLLM) para que razone respuestas nuevas basadas en las transcripciones, en lugar de solo buscar coincidencias.
*   **An√°lisis de Sentimiento:** Detectar si el usuario est√° triste al hablar y adaptar el tono del avatar.

### üîÆ Largo Plazo (Visi√≥n Completa)
*   **Video Avatar (Deepfake √âtico):** Animar la foto est√°tica para que mueva los labios sincronizados con el audio (Lip Sync).
*   **Realidad Aumentada:** Proyectar el avatar en el entorno del usuario.

## 5. Conclusi√≥n T√©cnica
La aplicaci√≥n ha pivotado exitosamente de un chatbot de texto convencional a una **plataforma de preservaci√≥n biomec√°nica**. La arquitectura actual es robusta para el MVP, centrada en la privacidad (Local-First) y la experiencia de usuario (Voice-First UI). La base de c√≥digo es modular, permitiendo conectar servicios de IA en la nube en el futuro sin reescribir el frontend.
